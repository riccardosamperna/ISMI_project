{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "c6319b06-e6bd-91a6-f1fb-62a2288a49d8",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "train\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"./cropped_input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "a8dcc109-9ea9-11d0-9eb8-d195c0dcc67b",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type_1\n",
      "Type_2\n",
      "Type_3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"./cropped_input/train\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "7c8b65d1-9e08-1121-958c-bc8442af5a26",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "train= glob.glob(\"./cropped_input/train/**/*.jpg\")#+glob.glob(\"../input/additional/**/*.jpg\")\n",
    "train = pd.DataFrame([[p.split('/')[3],p.split('/')[4],p] for p in train], columns = ['type','image','path'])\n",
    "test = glob.glob(\"./cropped_input/test/*.jpg\")\n",
    "test = pd.DataFrame([[p.split('/')[3],p] for p in test], columns = ['image','path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "4496b4a6-2b5e-79a6-78c4-d40d0934b9de",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x133de9d68>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAawAAAEeCAYAAADWyiHSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9pf3ToXpkc4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a636940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import ImageFilter, ImageStat, Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "\n",
    "types = train.groupby('type', as_index=False).count()\n",
    "types.plot(kind='bar', x='type', y='path', figsize=(7,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "3be2df98-df97-ce0c-054e-ecadfa9403fd",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>image</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Type_1</td>\n",
       "      <td>249</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Type_2</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Type_3</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     type  image  path\n",
       "0  Type_1    249   249\n",
       "1  Type_2    780   780\n",
       "2  Type_3    449   449"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "81d9ddc1-1adb-231e-c04b-432d4894528a",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbIAAAEgCAYAAADR3fZUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a62e7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "def im_multi(path):\n",
    "    try:\n",
    "        im_stats_im_ = Image.open(path)\n",
    "        return [path, {'size': im_stats_im_.size}]\n",
    "    except:\n",
    "        print(path)\n",
    "        return [path, {'size': [0,0]}]\n",
    "\n",
    "def im_stats(im_stats_df):\n",
    "    im_stats_d = {}\n",
    "    p = Pool(cpu_count())\n",
    "    ret = p.map(im_multi, im_stats_df['path'])\n",
    "    for i in range(len(ret)):\n",
    "        im_stats_d[ret[i][0]] = ret[i][1]\n",
    "    im_stats_df['size'] = im_stats_df['path'].map(lambda x: ' '.join(str(s) for s in im_stats_d[x]['size']))\n",
    "    return im_stats_df\n",
    "\n",
    "train = im_stats(train)\n",
    "sizes = train.groupby('size', as_index=False)['path'].count()\n",
    "_ = sizes.plot(kind='bar', x='size', y='path', figsize=(7,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "e98204d4-3fed-4770-1b9b-1011fee0b3ee",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200 200</td>\n",
       "      <td>1478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      size  path\n",
       "0  200 200  1478"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "f9452504-bac2-67d8-b367-d9629d4ed944",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1478\n",
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "[CV] opt_=adadelta, batch_size=15, nb_epoch=10 .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riccardosamperna/Programming/anaconda2/envs/python35/lib/python3.5/site-packages/ipykernel/__main__.py:45: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4s - loss: 1.0755 - acc: 0.4864\n",
      "Epoch 2/10\n",
      "4s - loss: 1.0005 - acc: 0.5190\n",
      "Epoch 3/10\n",
      "3s - loss: 1.0479 - acc: 0.5000\n",
      "Epoch 4/10\n",
      "3s - loss: 0.9450 - acc: 0.5203\n",
      "Epoch 5/10\n",
      "3s - loss: 0.9527 - acc: 0.5352\n",
      "Epoch 6/10\n",
      "3s - loss: 0.9318 - acc: 0.5772\n",
      "Epoch 7/10\n",
      "3s - loss: 0.9292 - acc: 0.5312\n",
      "Epoch 8/10\n",
      "4s - loss: 0.9111 - acc: 0.5528\n",
      "Epoch 9/10\n",
      "4s - loss: 0.9018 - acc: 0.5556\n",
      "Epoch 10/10\n",
      "3s - loss: 0.8823 - acc: 0.5867\n",
      "[CV]  opt_=adadelta, batch_size=15, nb_epoch=10, score=0.439189, total= 1.0min\n",
      "[CV] opt_=adadelta, batch_size=15, nb_epoch=10 .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.1min remaining:    0.0s\n",
      "/Users/riccardosamperna/Programming/anaconda2/envs/python35/lib/python3.5/site-packages/ipykernel/__main__.py:45: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4s - loss: 1.0558 - acc: 0.5027\n",
      "Epoch 2/10\n",
      "3s - loss: 0.9658 - acc: 0.5554\n",
      "Epoch 3/10\n",
      "3s - loss: 0.9478 - acc: 0.5243\n",
      "Epoch 4/10\n",
      "3s - loss: 0.9093 - acc: 0.5595\n",
      "Epoch 5/10\n",
      "3s - loss: 0.8887 - acc: 0.5716\n",
      "Epoch 6/10\n",
      "3s - loss: 0.9033 - acc: 0.5770\n",
      "Epoch 7/10\n",
      "4s - loss: 0.8985 - acc: 0.5554\n",
      "Epoch 8/10\n",
      "3s - loss: 0.8797 - acc: 0.5919\n",
      "Epoch 9/10\n",
      "3s - loss: 0.8654 - acc: 0.5959\n",
      "Epoch 10/10\n",
      "3s - loss: 0.8528 - acc: 0.6176\n",
      "[CV]  opt_=adadelta, batch_size=15, nb_epoch=10, score=0.455285, total=  45.3s\n",
      "[CV] opt_=sgd, batch_size=15, nb_epoch=10 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4s - loss: 12.9610 - acc: 0.1829\n",
      "Epoch 2/10\n",
      "3s - loss: 10.3267 - acc: 0.3591\n",
      "Epoch 3/10\n",
      "3s - loss: 7.6004 - acc: 0.5285\n",
      "Epoch 4/10\n",
      "3s - loss: 7.6004 - acc: 0.5285\n",
      "Epoch 5/10\n",
      "3s - loss: 7.6004 - acc: 0.5285\n",
      "Epoch 6/10\n",
      "3s - loss: 7.6004 - acc: 0.5285\n",
      "Epoch 7/10\n",
      "3s - loss: 7.6004 - acc: 0.5285\n",
      "Epoch 8/10\n",
      "3s - loss: 7.6004 - acc: 0.5285\n",
      "Epoch 9/10\n",
      "3s - loss: 7.6004 - acc: 0.5285\n",
      "Epoch 10/10\n",
      "3s - loss: 7.6004 - acc: 0.5285\n",
      "[CV]  opt_=sgd, batch_size=15, nb_epoch=10, score=0.527027, total=  48.8s\n",
      "[CV] opt_=sgd, batch_size=15, nb_epoch=10 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  2.7min remaining:    0.0s\n",
      "/Users/riccardosamperna/Programming/anaconda2/envs/python35/lib/python3.5/site-packages/ipykernel/__main__.py:45: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3s - loss: 9.6117 - acc: 0.3770\n",
      "Epoch 2/10\n",
      "3s - loss: 11.2173 - acc: 0.3041\n",
      "Epoch 3/10\n",
      "3s - loss: 11.2173 - acc: 0.3041\n",
      "Epoch 4/10\n",
      "4s - loss: 11.2173 - acc: 0.3041\n",
      "Epoch 5/10\n",
      "4s - loss: 11.2173 - acc: 0.3041\n",
      "Epoch 6/10\n",
      "4s - loss: 11.2173 - acc: 0.3041\n",
      "Epoch 7/10\n",
      "4s - loss: 11.2173 - acc: 0.3041\n",
      "Epoch 8/10\n",
      "4s - loss: 11.2173 - acc: 0.3041\n",
      "Epoch 9/10\n",
      "3s - loss: 11.2173 - acc: 0.3041\n",
      "Epoch 10/10\n",
      "3s - loss: 11.2173 - acc: 0.3041\n",
      "[CV]  opt_=sgd, batch_size=15, nb_epoch=10, score=0.303523, total=  47.8s\n",
      "[CV] opt_=adagrad, batch_size=15, nb_epoch=10 ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  3.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4s - loss: 13.1736 - acc: 0.1707\n",
      "Epoch 2/10\n",
      "4s - loss: 13.4099 - acc: 0.1680\n",
      "Epoch 3/10\n",
      "3s - loss: 13.4099 - acc: 0.1680\n",
      "Epoch 4/10\n",
      "4s - loss: 13.4099 - acc: 0.1680\n",
      "Epoch 5/10\n",
      "3s - loss: 13.4099 - acc: 0.1680\n",
      "Epoch 6/10\n",
      "3s - loss: 13.4099 - acc: 0.1680\n",
      "Epoch 7/10\n",
      "3s - loss: 13.4099 - acc: 0.1680\n",
      "Epoch 8/10\n",
      "3s - loss: 13.4099 - acc: 0.1680\n",
      "Epoch 9/10\n",
      "4s - loss: 13.4099 - acc: 0.1680\n",
      "Epoch 10/10\n",
      "4s - loss: 13.4099 - acc: 0.1680\n",
      "[CV]  opt_=adagrad, batch_size=15, nb_epoch=10, score=0.168919, total=  53.9s\n",
      "[CV] opt_=adagrad, batch_size=15, nb_epoch=10 ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  4.5min remaining:    0.0s\n",
      "/Users/riccardosamperna/Programming/anaconda2/envs/python35/lib/python3.5/site-packages/ipykernel/__main__.py:45: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4s - loss: 13.1416 - acc: 0.1730\n",
      "Epoch 2/10\n",
      "4s - loss: 13.3954 - acc: 0.1689\n",
      "Epoch 3/10\n",
      "3s - loss: 13.3954 - acc: 0.1689\n",
      "Epoch 4/10\n",
      "3s - loss: 13.3954 - acc: 0.1689\n",
      "Epoch 5/10\n",
      "3s - loss: 13.3954 - acc: 0.1689\n",
      "Epoch 6/10\n",
      "3s - loss: 13.3954 - acc: 0.1689\n",
      "Epoch 7/10\n",
      "3s - loss: 13.3954 - acc: 0.1689\n",
      "Epoch 8/10\n",
      "3s - loss: 13.3954 - acc: 0.1689\n",
      "Epoch 9/10\n",
      "3s - loss: 13.3954 - acc: 0.1689\n",
      "Epoch 10/10\n",
      "3s - loss: 13.3954 - acc: 0.1689\n",
      "[CV]  opt_=adagrad, batch_size=15, nb_epoch=10, score=0.168022, total=  44.0s\n",
      "[CV] opt_=adam, batch_size=15, nb_epoch=10 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  5.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4s - loss: 1.2504 - acc: 0.4688\n",
      "Epoch 2/10\n",
      "3s - loss: 1.1234 - acc: 0.4946\n",
      "Epoch 3/10\n",
      "4s - loss: 1.0240 - acc: 0.5312\n",
      "Epoch 4/10\n",
      "3s - loss: 0.9710 - acc: 0.5366\n",
      "Epoch 5/10\n",
      "4s - loss: 0.9059 - acc: 0.5718\n",
      "Epoch 6/10\n",
      "3s - loss: 1.0223 - acc: 0.5271\n",
      "Epoch 7/10\n",
      "4s - loss: 1.0373 - acc: 0.5393\n",
      "Epoch 8/10\n",
      "3s - loss: 0.9829 - acc: 0.5528\n",
      "Epoch 9/10\n",
      "3s - loss: 0.9254 - acc: 0.5379\n",
      "Epoch 10/10\n",
      "4s - loss: 0.9647 - acc: 0.5447\n",
      "[CV]  opt_=adam, batch_size=15, nb_epoch=10, score=0.575676, total=  52.7s\n",
      "[CV] opt_=adam, batch_size=15, nb_epoch=10 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  6.2min remaining:    0.0s\n",
      "/Users/riccardosamperna/Programming/anaconda2/envs/python35/lib/python3.5/site-packages/ipykernel/__main__.py:45: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3s - loss: 1.3547 - acc: 0.4878\n",
      "Epoch 2/10\n",
      "3s - loss: 0.9628 - acc: 0.5527\n",
      "Epoch 3/10\n",
      "3s - loss: 0.9185 - acc: 0.5689\n",
      "Epoch 4/10\n",
      "3s - loss: 0.9629 - acc: 0.5568\n",
      "Epoch 5/10\n",
      "3s - loss: 0.9066 - acc: 0.5878\n",
      "Epoch 6/10\n",
      "3s - loss: 0.9365 - acc: 0.5824\n",
      "Epoch 7/10\n",
      "4s - loss: 0.9107 - acc: 0.5703\n",
      "Epoch 8/10\n",
      "5s - loss: 0.8722 - acc: 0.5959\n",
      "Epoch 9/10\n",
      "3s - loss: 0.9716 - acc: 0.6068\n",
      "Epoch 10/10\n",
      "3s - loss: 0.9784 - acc: 0.5689\n",
      "[CV]  opt_=adam, batch_size=15, nb_epoch=10, score=0.578591, total=  48.6s\n",
      "[CV] opt_=adamax, batch_size=15, nb_epoch=10 .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  7.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4s - loss: 1.4560 - acc: 0.4783\n",
      "Epoch 2/10\n",
      "4s - loss: 1.0400 - acc: 0.4864\n",
      "Epoch 3/10\n",
      "3s - loss: 0.9797 - acc: 0.5081\n",
      "Epoch 4/10\n",
      "3s - loss: 0.9534 - acc: 0.5379\n",
      "Epoch 5/10\n",
      "3s - loss: 0.9284 - acc: 0.5488\n",
      "Epoch 6/10\n",
      "4s - loss: 0.9310 - acc: 0.5447\n",
      "Epoch 7/10\n",
      "3s - loss: 0.9683 - acc: 0.5352\n",
      "Epoch 8/10\n",
      "3s - loss: 0.9537 - acc: 0.5515\n",
      "Epoch 9/10\n",
      "3s - loss: 0.9166 - acc: 0.5650\n",
      "Epoch 10/10\n",
      "4s - loss: 0.8955 - acc: 0.5691\n",
      "[CV]  opt_=adamax, batch_size=15, nb_epoch=10, score=0.597297, total=  47.3s\n",
      "[CV] opt_=adamax, batch_size=15, nb_epoch=10 .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  7.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4s - loss: 3.0371 - acc: 0.4257\n",
      "Epoch 2/10\n",
      "3s - loss: 1.0888 - acc: 0.4703\n",
      "Epoch 3/10\n",
      "4s - loss: 0.9285 - acc: 0.5541\n",
      "Epoch 4/10\n",
      "4s - loss: 0.9065 - acc: 0.5676\n",
      "Epoch 5/10\n",
      "4s - loss: 0.9295 - acc: 0.5622\n",
      "Epoch 6/10\n",
      "4s - loss: 0.8713 - acc: 0.6000\n",
      "Epoch 7/10\n",
      "3s - loss: 0.8842 - acc: 0.5784\n",
      "Epoch 8/10\n",
      "4s - loss: 0.8921 - acc: 0.5622\n",
      "Epoch 9/10\n",
      "4s - loss: 0.8842 - acc: 0.5824\n",
      "Epoch 10/10\n",
      "3s - loss: 0.8490 - acc: 0.6122\n",
      "[CV]  opt_=adamax, batch_size=15, nb_epoch=10, score=0.573171, total=  48.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  8.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  8.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8s - loss: 7.7135 - acc: 0.4986\n",
      "Epoch 2/10\n",
      "8s - loss: 7.6119 - acc: 0.5277\n",
      "Epoch 3/10\n",
      "7s - loss: 7.6119 - acc: 0.5277\n",
      "Epoch 4/10\n",
      "8s - loss: 7.6119 - acc: 0.5277\n",
      "Epoch 5/10\n",
      "7s - loss: 7.6119 - acc: 0.5277\n",
      "Epoch 6/10\n",
      "8s - loss: 7.6119 - acc: 0.5277\n",
      "Epoch 7/10\n",
      "8s - loss: 7.6119 - acc: 0.5277\n",
      "Epoch 8/10\n",
      "8s - loss: 7.6119 - acc: 0.5277\n",
      "Epoch 9/10\n",
      "8s - loss: 7.6119 - acc: 0.5277\n",
      "Epoch 10/10\n",
      "11s - loss: 7.6119 - acc: 0.5277\n",
      "Best: 0.585250 using {'opt_': 'adamax', 'batch_size': 15, 'nb_epoch': 10}\n",
      "0.447237 (0.008048) with: {'opt_': 'adadelta', 'batch_size': 15, 'nb_epoch': 10}\n",
      "0.415275 (0.111752) with: {'opt_': 'sgd', 'batch_size': 15, 'nb_epoch': 10}\n",
      "0.168470 (0.000449) with: {'opt_': 'adagrad', 'batch_size': 15, 'nb_epoch': 10}\n",
      "0.577133 (0.001458) with: {'opt_': 'adam', 'batch_size': 15, 'nb_epoch': 10}\n",
      "0.585234 (0.012063) with: {'opt_': 'adamax', 'batch_size': 15, 'nb_epoch': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riccardosamperna/Programming/anaconda2/envs/python35/lib/python3.5/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, ZeroPadding2D, MaxPooling2D\n",
    "from keras import optimizers\n",
    "\n",
    "def get_im_cv2(path):\n",
    "    img = cv2.imread(path)\n",
    "    resized = cv2.resize(img, (200, 200), cv2.INTER_LINEAR)\n",
    "    return [path, resized]\n",
    "\n",
    "def normalize_image_features(paths):\n",
    "    imf_d = {}\n",
    "    p = Pool(cpu_count())\n",
    "    ret = p.map(get_im_cv2, paths)\n",
    "    for i in range(len(ret)):\n",
    "        imf_d[ret[i][0]] = ret[i][1]\n",
    "    ret = []\n",
    "    fdata = [imf_d[f] for f in paths]\n",
    "    fdata = np.array(fdata, dtype=np.uint8)\n",
    "    fdata = fdata.transpose((0, 3, 1, 2))\n",
    "    fdata = fdata.astype('float32')\n",
    "    fdata = fdata / 255\n",
    "    return fdata\n",
    "\n",
    "#train = glob.glob('../input/train/**/*.jpg') + glob.glob('../input/additional/**/*.jpg')\n",
    "print(len(train))\n",
    "#train = pd.DataFrame([[p.split('/')[3],p.split('/')[4],p] for p in train], columns = ['type','image','path'])\n",
    "train = train[train['size'] != '0 0'].reset_index(drop=True) #remove bad images\n",
    "train_data = normalize_image_features(train['path'])\n",
    "#np.save('train.npy', train_data, allow_pickle=True, fix_imports=True)\n",
    "#train_data = np.load('train.npy')\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_target = le.fit_transform(train['type'].values)\n",
    "#np.save('train_target.npy', train_target, allow_pickle=True, fix_imports=True)\n",
    "#train_target = np.load('train_target.npy')\n",
    "\n",
    "def create_model(opt_):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1, 1), input_shape=(3, 200, 200)))\n",
    "    model.add(Convolution2D(8, 3, 3))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(12))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(6))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=opt_, loss='sparse_categorical_crossentropy', metrics=['accuracy']) #loss='binary_crossentropy' not working\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, nb_epoch=10, batch_size=15, verbose=2)\n",
    "opts_ = ['adadelta','sgd','adagrad','adam','adamax']\n",
    "epochs = np.array([10])\n",
    "batches = np.array([15])\n",
    "param_grid = dict(nb_epoch=epochs, batch_size=batches, opt_=opts_)\n",
    "grid = GridSearchCV(estimator=model, cv=StratifiedKFold(n_splits=2), param_grid=param_grid, verbose=20)\n",
    "grid_result = grid.fit(train_data, train_target)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "for params, mean_score, scores in grid_result.grid_scores_:\n",
    "    print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))\n",
    "#print(\"Log Loss...\", log_loss(train_target, grid_result.predict(train_data)))\n",
    "\n",
    "test_data = normalize_image_features(test['path'])\n",
    "#np.save('test.npy', test_data, allow_pickle=True, fix_imports=True)\n",
    "#test_data = np.load('test.npy')\n",
    "test_id = test.image.values\n",
    "#np.save('test_id.npy', test_id, allow_pickle=True, fix_imports=True)\n",
    "#test_id = np.load('test_id.npy')\n",
    "\n",
    "pred = grid_result.predict_proba(test_data)\n",
    "df = pd.DataFrame(pred, columns=le.classes_)\n",
    "df['image_name'] = test_id\n",
    "df.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 85,
  "_is_fork": false,
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [python35]",
   "language": "python",
   "name": "Python [python35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
