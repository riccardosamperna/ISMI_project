{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c6319b06-e6bd-91a6-f1fb-62a2288a49d8",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from subprocess import check_output\n",
    "#print(check_output([\"ls\", \"./humanclassifier\"]).decode(\"utf8\"))\n",
    "print(check_output([\"ls\", \"./input\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a8dcc109-9ea9-11d0-9eb8-d195c0dcc67b",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"./cropped_input/additional\"]).decode(\"utf8\"))\n",
    "#print(check_output([\"ls\", \"./input/train\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7c8b65d1-9e08-1121-958c-bc8442af5a26",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "train= glob.glob(\"./all_images_300/train/**/*.jpg\") #+ glob.glob(\"./all_images_300/additional/**/*.jpg\")\n",
    "#train= glob.glob(\"./input/train/**/*.jpg\")#+glob.glob(\"./input/additional/**/*.jpg\")\n",
    "train = pd.DataFrame([[p.split('/')[3],p.split('/')[4],p] for p in train], columns = ['type','image','path'])\n",
    "test = glob.glob(\"./all_images_300/test/*.jpg\") + glob.glob(\"./all_images_300/test_stg2/*.jpg\")\n",
    "#test = glob.glob(\"./input/test/*.jpg\")\n",
    "test = pd.DataFrame([[p.split('/')[3],p] for p in test], columns = ['image','path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "train = glob.glob(\"./all_images_300/train/**/*.jpg\")\n",
    "train = pd.DataFrame([[p.split('/')[3],p.split('/')[4],p] for p in train], columns = ['type','image','path'])\n",
    "test = glob.glob(\"./humanclassifier/All_categories/*.jpg\")\n",
    "test = pd.DataFrame([[p.split('/')[3],p] for p in test], columns = ['image','path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train[train.image.isin(test.image)].type.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#csv file containing similar images between additional and test set\n",
    "#create a list of the additional dataset images to remove from training set\n",
    "import csv\n",
    "to_remove = []\n",
    "with open('./input/test_duplicates_v3.csv', 'r') as csvfile:\n",
    "    csvreader = csv.reader(csvfile, delimiter=',')\n",
    "    next(csvreader)\n",
    "    for row in csvreader:\n",
    "        aux = row[1].split('/')\n",
    "        to_remove.append(aux[-1])\n",
    "unique_values = set(to_remove)\n",
    "to_remove_unique = list(unique_values)\n",
    "print(len(to_remove_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clean training set\n",
    "train = train[~train.image.isin(to_remove_unique)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4496b4a6-2b5e-79a6-78c4-d40d0934b9de",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFilter, ImageStat, Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "\n",
    "types = train.groupby('type', as_index=False).count()\n",
    "types.plot(kind='bar', x='type', y='path', figsize=(7,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3be2df98-df97-ce0c-054e-ecadfa9403fd",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "81d9ddc1-1adb-231e-c04b-432d4894528a",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "def im_multi(path):\n",
    "    try:\n",
    "        im_stats_im_ = Image.open(path)\n",
    "        return [path, {'size': im_stats_im_.size}]\n",
    "    except:\n",
    "        print(path)\n",
    "        return [path, {'size': [0,0]}]\n",
    "\n",
    "def im_stats(im_stats_df):\n",
    "    im_stats_d = {}\n",
    "    p = Pool(cpu_count())\n",
    "    ret = p.map(im_multi, im_stats_df['path'])\n",
    "    for i in range(len(ret)):\n",
    "        im_stats_d[ret[i][0]] = ret[i][1]\n",
    "    im_stats_df['size'] = im_stats_df['path'].map(lambda x: ' '.join(str(s) for s in im_stats_d[x]['size']))\n",
    "    return im_stats_df\n",
    "\n",
    "train = im_stats(train)\n",
    "sizes = train.groupby('size', as_index=False)['path'].count()\n",
    "_ = sizes.plot(kind='bar', x='size', y='path', figsize=(7,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e98204d4-3fed-4770-1b9b-1011fee0b3ee",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f9452504-bac2-67d8-b367-d9629d4ed944",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test bed for first architecture\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, ZeroPadding2D, MaxPooling2D\n",
    "from keras import optimizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "# from keras import backend as K\n",
    "# K.set_image_dim_ordering('th')\n",
    "\n",
    "def get_im_cv2(path):\n",
    "    img = cv2.imread(path)\n",
    "    resized = cv2.resize(img, (200, 200), cv2.INTER_LINEAR)\n",
    "    return [path, resized]\n",
    "    #return [path, img]\n",
    "\n",
    "def normalize_image_features(paths):\n",
    "    imf_d = {}\n",
    "    p = Pool(cpu_count())\n",
    "    ret = p.map(get_im_cv2, paths)\n",
    "    for i in range(len(ret)):\n",
    "        imf_d[ret[i][0]] = ret[i][1]\n",
    "    ret = []\n",
    "    fdata = [imf_d[f] for f in paths]\n",
    "    fdata = np.array(fdata, dtype=np.uint8)\n",
    "    fdata = fdata.transpose((0, 3, 1, 2))\n",
    "    fdata = fdata.astype('float32')\n",
    "    fdata = fdata / 255\n",
    "    return fdata\n",
    "\n",
    "#train = glob.glob('../input/train/**/*.jpg') + glob.glob('../input/additional/**/*.jpg')\n",
    "print(len(train))\n",
    "#train = pd.DataFrame([[p.split('/')[3],p.split('/')[4],p] for p in train], columns = ['type','image','path'])\n",
    "#train = train[train['size'] != '0 0'].reset_index(drop=True) #remove bad images\n",
    "train_data = normalize_image_features(train['path'])\n",
    "#np.save('train.npy', train_data, allow_pickle=True, fix_imports=True)\n",
    "#train_data = np.load('train.npy')\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_target = le.fit_transform(train['type'].values)\n",
    "#np.save('train_target.npy', train_target, allow_pickle=True, fix_imports=True)\n",
    "#train_target = np.load('train_target.npy')\n",
    "\n",
    "def create_model(opt_):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1, 1), input_shape=(3, 200, 200)))\n",
    "    model.add(Convolution2D(8, 3, 3))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(12))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(6))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "#     model = Sequential()\n",
    "#     model.add(ZeroPadding2D((1, 1), input_shape=(3, 200, 200)))\n",
    "#     model.add(Convolution2D(32, 3, 3))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\"))\n",
    "\n",
    "#     model.add(Conv2D(32, 3, 3))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\"))\n",
    "\n",
    "#     model.add(Conv2D(64, 3, 3))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\"))\n",
    "    \n",
    "#     model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "#     model.add(Dense(64))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=opt_, loss='sparse_categorical_crossentropy', metrics=['accuracy']) #loss='binary_crossentropy' not working\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, nb_epoch=100, batch_size=15, verbose=2)\n",
    "#model = KerasClassifier(build_fn=create_model, verbose=2)\n",
    "opts_ = ['adamax'] #['adadelta','sgd','adagrad','adam','adamax'] #['adamax']\n",
    "epochs = np.array([100])\n",
    "#epochs = [10, 50, 100]\n",
    "batches = np.array([15])\n",
    "#batches = [5, 10, 15, 20]\n",
    "param_grid = dict(nb_epoch=epochs, batch_size=batches, opt_=opts_)\n",
    "grid = GridSearchCV(estimator=model, cv=StratifiedKFold(n_splits=2), param_grid=param_grid, verbose=20)\n",
    "grid_result = grid.fit(train_data, train_target)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "for params, mean_score, scores in grid_result.grid_scores_:\n",
    "    print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))\n",
    "#print(\"Log Loss...\", log_loss(train_target, grid_result.predict(train_data)))\n",
    "\n",
    "test_data = normalize_image_features(test['path'])\n",
    "#np.save('test.npy', test_data, allow_pickle=True, fix_imports=True)\n",
    "#test_data = np.load('test.npy')\n",
    "test_id = test.image.values\n",
    "#np.save('test_id.npy', test_id, allow_pickle=True, fix_imports=True)\n",
    "#test_id = np.load('test_id.npy')\n",
    "\n",
    "pred = grid_result.predict_proba(test_data)\n",
    "df = pd.DataFrame(pred, columns=le.classes_)\n",
    "df['image_name'] = test_id\n",
    "df.to_csv('submission2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Starting test bed for final architecture with k-fold cross validation\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, ZeroPadding2D, MaxPooling2D\n",
    "from keras import optimizers\n",
    "\n",
    "def get_im_cv2(path):\n",
    "    img = cv2.imread(path)\n",
    "    resized = cv2.resize(img, (64, 64), cv2.INTER_LINEAR)\n",
    "    return [path, resized]\n",
    "    #return [path, img]\n",
    "\n",
    "def normalize_image_features(paths):\n",
    "    imf_d = {}\n",
    "    p = Pool(cpu_count())\n",
    "    ret = p.map(get_im_cv2, paths)\n",
    "    for i in range(len(ret)):\n",
    "        imf_d[ret[i][0]] = ret[i][1]\n",
    "    ret = []\n",
    "    fdata = [imf_d[f] for f in paths]\n",
    "    fdata = np.array(fdata, dtype=np.uint8)\n",
    "    fdata = fdata.transpose((0, 3, 1, 2))\n",
    "    fdata = fdata.astype('float32')\n",
    "    fdata = fdata / 255\n",
    "    return fdata\n",
    "\n",
    "#train = glob.glob('../input/train/**/*.jpg') + glob.glob('../input/additional/**/*.jpg')\n",
    "print(len(train))\n",
    "#train = pd.DataFrame([[p.split('/')[3],p.split('/')[4],p] for p in train], columns = ['type','image','path'])\n",
    "#train = train[train['size'] != '0 0'].reset_index(drop=True) #remove bad images\n",
    "train_data = normalize_image_features(train['path'])\n",
    "#np.save('train.npy', train_data, allow_pickle=True, fix_imports=True)\n",
    "#train_data = np.load('train.npy')\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_target = le.fit_transform(train['type'].values)\n",
    "#np.save('train_target.npy', train_target, allow_pickle=True, fix_imports=True)\n",
    "#train_target = np.load('train_target.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Final architecure\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers import Activation, BatchNormalization\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "def create_model(opt_):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(4, 3, 3, activation='relu', dim_ordering='th', input_shape=(3, 64, 64))) #use input_shape=(3, 64, 64)\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), dim_ordering='th'))\n",
    "    model.add(Convolution2D(8, 3, 3, activation='relu', dim_ordering='th'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), dim_ordering='th'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(16, activation='tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=opt_, loss='sparse_categorical_crossentropy', metrics=['accuracy']) #loss='binary_crossentropy' not working\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, nb_epoch=100, batch_size=15, verbose=2)\n",
    "#model = KerasClassifier(build_fn=create_model, nb_epoch=100, verbose=2)\n",
    "opts_ = ['adagrad']#['adadelta','sgd','adagrad','adam','adamax'] #['adamax']\n",
    "epochs = np.array([100])\n",
    "#epochs = [10, 50, 100]\n",
    "batches = np.array([15])\n",
    "#batches = [5, 10, 15, 20]\n",
    "param_grid = dict(nb_epoch=epochs, batch_size=batches, opt_=opts_)\n",
    "grid = GridSearchCV(estimator=model, cv=StratifiedKFold(n_splits=2), param_grid=param_grid, verbose=20)\n",
    "grid_result = grid.fit(train_data, train_target)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "for params, mean_score, scores in grid_result.grid_scores_:\n",
    "    print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))\n",
    "print(\"Log Loss...\", log_loss(train_target, grid_result.predict_proba(train_data)))\n",
    "\n",
    "test_data = normalize_image_features(test['path'])\n",
    "#np.save('test.npy', test_data, allow_pickle=True, fix_imports=True)\n",
    "#test_data = np.load('test.npy')\n",
    "test_id = test.image.values\n",
    "#np.save('test_id.npy', test_id, allow_pickle=True, fix_imports=True)\n",
    "#test_id = np.load('test_id.npy')\n",
    "\n",
    "pred = grid_result.predict_proba(test_data)\n",
    "df = pd.DataFrame(pred, columns=le.classes_)\n",
    "df['image_name'] = test_id\n",
    "df.to_csv('human_accuracy_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_target = le.fit_transform(train[train.image.isin(test.image)].type.values)\n",
    "print(\"Log Loss...\", log_loss(test_target, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "from sklearn_evaluation import plot\n",
    "plot.grid_search(grid.grid_scores_, change='nb_epoch', kind='bar')"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 85,
  "_is_fork": false,
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [python35]",
   "language": "python",
   "name": "Python [python35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
