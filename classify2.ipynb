{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"./all_images_300\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFilter, ImageStat, Image, ImageDraw\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "from matplotlib import pyplot as pp\n",
    "from matplotlib import colors as pc\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def im_multi(path):\n",
    "    try:\n",
    "        im_stats_im_ = Image.open(path)\n",
    "        return [path, {'size': im_stats_im_.size}]\n",
    "    except:\n",
    "        print(path)\n",
    "        return [path, {'size': [0,0]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def im_stats(im_stats_df):\n",
    "    im_stats_d = {}\n",
    "    p = Pool(cpu_count())\n",
    "    ret = p.map(im_multi, im_stats_df['path'])\n",
    "    for i in range(len(ret)):\n",
    "        im_stats_d[ret[i][0]] = ret[i][1]\n",
    "    im_stats_df['size'] = im_stats_df['path'].map(lambda x: ' '.join(str(s) for s in im_stats_d[x]['size']))\n",
    "    return im_stats_df\n",
    "\n",
    "def get_im_cv2(path):\n",
    "    img = cv2.imread(path)\n",
    "    #resized = cv2.resize(img, (64, 64), cv2.INTER_LINEAR) #use cv2.resize(img, (64, 64), cv2.INTER_LINEAR)\n",
    "    #return [path, resized]\n",
    "    return [path, img]\n",
    "\n",
    "def normalize_image_features(paths):\n",
    "    imf_d = {}\n",
    "    p = Pool(cpu_count())\n",
    "    ret = p.map(get_im_cv2, paths)\n",
    "    for i in range(len(ret)):\n",
    "        imf_d[ret[i][0]] = ret[i][1]\n",
    "    ret = []\n",
    "    fdata = [imf_d[f] for f in paths]\n",
    "    fdata = np.array(fdata, dtype=np.uint8)\n",
    "    fdata = fdata.transpose((0, 3, 1, 2))\n",
    "    fdata = fdata.astype('float32')\n",
    "    fdata = fdata / 255\n",
    "    return fdata\n",
    "\n",
    "print('Start pre-processing training set')\n",
    "train = glob.glob('./all_images_300/train/**/*.jpg') + glob.glob('./all_images_300/additional/**/*.jpg')\n",
    "#train=glob.glob('../input/train/Type_1/*.jpg')[:5] +glob.glob('../input/train/Type_2/*.jpg')[:5] +glob.glob('../input/train/Type_3/*.jpg')[:5]\n",
    "#train = glob.glob('./input/roi/train/**/*.jpg')\n",
    "train = pd.DataFrame([[p.split('/')[3],p.split('/')[4],p] for p in train], columns = ['type','image','path']) #limit for Kaggle Demo\n",
    "train = im_stats(train)\n",
    "#train = train[train['size'] != '0 0'].reset_index(drop=True) #remove bad images\n",
    "train_data = normalize_image_features(train['path'])\n",
    "#train_data = roi(pathtrain)\n",
    "#np.save('train64x64.npy', train_data, allow_pickle=True, fix_imports=True)\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_target = le.fit_transform(train['type'].values)\n",
    "print(le.classes_) #in case not 1 to 3 order\n",
    "#np.save('train_target64x64.npy', train_target, allow_pickle=True, fix_imports=True)\n",
    "\n",
    "print('Start pre-processing test set')\n",
    "test = glob.glob('./all_images_300/test/*.jpg') + glob.glob('./all_images_300/test_stg2/*.jpg')\n",
    "#test = glob.glob('./input/roi/test/*.jpg')\n",
    "test = pd.DataFrame([[p.split('/')[3],p] for p in test], columns = ['image','path']) #[::20] #limit for Kaggle Demo\n",
    "test_data = normalize_image_features(test['path'])\n",
    "#test_data=roi(pathtest)\n",
    "#np.save('test64x64.npy', test_data, allow_pickle=True, fix_imports=True)\n",
    "\n",
    "test_id = test.image.values\n",
    "#np.save('test_id64x64.npy', test_id, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test final architecure with simple cross-validation 70-30 split\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers.convolutional import Convolution2D, ZeroPadding2D, MaxPooling2D\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "K.set_floatx('float32')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(17)\n",
    "\n",
    "#train_data = np.load('train.npy')\n",
    "#train_target = np.load('train_target.npy')\n",
    "\n",
    "x_train,x_val_train,y_train,y_val_train = train_test_split(train_data,train_target,test_size=0.3, random_state=17)\n",
    "\n",
    "def create_model(opt_='adadelta'):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(4, 3, 3, activation='relu', dim_ordering='th', input_shape=(3, 300, 300))) #use input_shape=(3, 64, 64)\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), dim_ordering='th'))\n",
    "    model.add(Convolution2D(8, 3, 3, activation='relu', dim_ordering='th'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), dim_ordering='th'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(12, activation='tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=opt_, loss='sparse_categorical_crossentropy', metrics=['accuracy']) \n",
    "    return model\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=0.3, zoom_range=0.3)\n",
    "datagen.fit(train_data)\n",
    "\n",
    "model = create_model()\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "model.fit_generator(datagen.flow(x_train,y_train, batch_size=15, shuffle=True), nb_epoch=50, samples_per_epoch=len(x_train), verbose=2, validation_data=(x_val_train, y_val_train))\n",
    "#model.fit(x_train,y_train, batch_size=15, nb_epoch=100, verbose=2, validation_data=(x_val_train, y_val_train))\n",
    "\n",
    "#test_data = np.load('test.npy')\n",
    "#test_id = np.load('test_id.npy')\n",
    "\n",
    "pred = model.predict_proba(test_data)\n",
    "df = pd.DataFrame(pred, columns=['Type_1','Type_2','Type_3'])\n",
    "df['image_name'] = test_id\n",
    "df.to_csv('submission_300.csv', index=False)\n",
    "\n",
    "\n",
    "print(cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Reshaped dataset to work with TensorFlow\n",
    "train_data = train_data.transpose((0, 2, 3, 1))\n",
    "test_data = test_data.transpose((0, 2, 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# VGG16 fine-tuning, did not work also tried to run on SurfSara\n",
    "from keras import applications\n",
    "from keras.models import Sequential, Model\n",
    "from keras import optimizers\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "x_train,x_val_train,y_train,y_val_train = train_test_split(train_data,train_target,test_size=0.3, random_state=17)\n",
    "\n",
    "# build the VGG16 network\n",
    "base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "print('Base-model loaded.')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='tanh'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(3, activation='softmax', name='predictions'))\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=0.3, zoom_range=0.3)\n",
    "datagen.fit(train_data)\n",
    "\n",
    "model.compile(optimizer='adamax', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(datagen.flow(x_train,y_train, batch_size=15, shuffle=True), nb_epoch=50, samples_per_epoch=len(x_train), verbose=2, validation_data=(x_val_train, y_val_train))\n",
    "\n",
    "print('Unfreeze layers!!!')\n",
    "\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[15:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=optimizers.SGD(lr=0.0001, momentum=0.9), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(datagen.flow(x_train,y_train, batch_size=15, shuffle=True), nb_epoch=50, samples_per_epoch=len(x_train), verbose=2, validation_data=(x_val_train, y_val_train))\n",
    "\n",
    "pred = model.predict_proba(test_data)\n",
    "df = pd.DataFrame(pred, columns=['Type_1','Type_2','Type_3'])\n",
    "df['image_name'] = test_id\n",
    "df.to_csv('submission_vgg_first.csv', index=False)\n",
    "\n",
    "\n",
    "print(cpu_count())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [python35]",
   "language": "python",
   "name": "Python [python35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
