{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn\n",
    "import sklearn.neighbors\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "import time\n",
    "import random\n",
    "import load_data\n",
    "\n",
    "import keras\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = './input'# define here the directory where you have your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification problem with 3 classes\n"
     ]
    }
   ],
   "source": [
    "# labels for the three classes in this classification problem.\n",
    "# These are the same names used in folders for raw training data\n",
    "cervixTypes = [\"Type_1\", \"Type_2\", \"Type_3\"]\n",
    "n_classes = len(cervixTypes)\n",
    "print('Classification problem with {} classes'.format(n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from hdf5 file\n",
      "\n",
      " Doooone :)\n"
     ]
    }
   ],
   "source": [
    "data, labels = load_data.load_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples_per_class = [249, 781, 450]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_training_validation_datasets(x, y, samples_per_class, val_percentage=0.3, val_balanced=True):\n",
    "    \"\"\"\n",
    "    Derive a training and a validation datasets from a given dataset with\n",
    "    data (x) and labels (y). By default, the validation set is 30% of the\n",
    "    training set, and it has balanced samples across classes. When balancing,\n",
    "    it takes the 30% of the class with less samples as reference.\n",
    "    \"\"\"\n",
    "    n_cv_samples_per_class = int(np.amin(samples_per_class) * 0.3)\n",
    "    \n",
    "    mask = np.zeros(x.shape[0], dtype=bool)\n",
    "    low = 0\n",
    "    high = 0\n",
    "     \n",
    "    for c in samples_per_class:\n",
    "        high = high + c\n",
    "        ids_cv = np.random.choice(np.arange(low,high),n_cv_samples_per_class, replace = False)\n",
    "        mask[ids_cv] = True\n",
    "        low = low + c   \n",
    "    \n",
    "    x_train = x[~mask,:, :, :]\n",
    "    y_train = y[~mask, :]\n",
    "\n",
    "    x_validation = x[mask,:, :, :]\n",
    "    y_validation = y[mask, :]\n",
    "    \n",
    "    return x_train, y_train, x_validation, y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_validation, y_validation = split_training_validation_datasets(data, labels, samples_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_classes = 3\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow(x_validation, y_validation, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 400, 400\n",
    "input_shape = (img_rows, img_cols, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1258/1258 [==============================] - 3787s  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "predict_generator() got an unexpected keyword argument 'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-588d907ec181>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mbottleneck_features_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bottleneck_features_validation.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottleneck_features_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: predict_generator() got an unexpected keyword argument 'batch_size'"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator()\n",
    "\n",
    "    # build the VGG16 network\n",
    "model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "bottleneck_features_train = model.predict(x_train, batch_size= batch_size, verbose=1)\n",
    "np.save(open('bottleneck_features_train.npy', 'w'), bottleneck_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/222 [==============================] - 650s    \n"
     ]
    }
   ],
   "source": [
    "bottleneck_features_validation = model.predict(x_validation, batch_size= batch_size, verbose=1)\n",
    "np.save(open('bottleneck_features_validation.npy', 'w'), bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(open('x_train.npy', 'w'), x_train)\n",
    "np.save(open('y_train.npy', 'w'), y_train)\n",
    "np.save(open('x_validation.npy', 'w'), x_validation)\n",
    "np.save(open('y_validation.npy', 'w'), y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1258 samples, validate on 222 samples\n",
      "Epoch 1/50\n",
      "1258/1258 [==============================] - 83s - loss: 1.9122 - acc: 0.5024 - val_loss: 1.1920 - val_acc: 0.3333\n",
      "Epoch 2/50\n",
      "1258/1258 [==============================] - 81s - loss: 1.0241 - acc: 0.5437 - val_loss: 1.1457 - val_acc: 0.3333\n",
      "Epoch 3/50\n",
      "1258/1258 [==============================] - 82s - loss: 0.9984 - acc: 0.5564 - val_loss: 1.1006 - val_acc: 0.3333\n",
      "Epoch 4/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.9988 - acc: 0.5485 - val_loss: 1.1846 - val_acc: 0.3333\n",
      "Epoch 5/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.9792 - acc: 0.5564 - val_loss: 1.2898 - val_acc: 0.3378\n",
      "Epoch 6/50\n",
      "1258/1258 [==============================] - 82s - loss: 0.9550 - acc: 0.5723 - val_loss: 1.2049 - val_acc: 0.3333\n",
      "Epoch 7/50\n",
      "1258/1258 [==============================] - 83s - loss: 0.9460 - acc: 0.5660 - val_loss: 1.2876 - val_acc: 0.3333\n",
      "Epoch 8/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.9269 - acc: 0.5739 - val_loss: 1.2353 - val_acc: 0.3514\n",
      "Epoch 9/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.9149 - acc: 0.5723 - val_loss: 1.2336 - val_acc: 0.3333\n",
      "Epoch 10/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.9003 - acc: 0.5715 - val_loss: 1.6813 - val_acc: 0.3333\n",
      "Epoch 11/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.9024 - acc: 0.5723 - val_loss: 1.3949 - val_acc: 0.3378\n",
      "Epoch 12/50\n",
      "1258/1258 [==============================] - 108s - loss: 0.8925 - acc: 0.5747 - val_loss: 1.2832 - val_acc: 0.3333\n",
      "Epoch 13/50\n",
      "1258/1258 [==============================] - 88s - loss: 0.8704 - acc: 0.5795 - val_loss: 1.1791 - val_acc: 0.3694\n",
      "Epoch 14/50\n",
      "1258/1258 [==============================] - 82s - loss: 0.8626 - acc: 0.5851 - val_loss: 1.5509 - val_acc: 0.3423\n",
      "Epoch 15/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.8502 - acc: 0.6033 - val_loss: 1.3425 - val_acc: 0.3333\n",
      "Epoch 16/50\n",
      "1258/1258 [==============================] - 82s - loss: 0.8211 - acc: 0.6057 - val_loss: 1.3687 - val_acc: 0.3468\n",
      "Epoch 17/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.8325 - acc: 0.5795 - val_loss: 1.6096 - val_acc: 0.3468\n",
      "Epoch 18/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.8256 - acc: 0.6137 - val_loss: 1.2374 - val_acc: 0.4099\n",
      "Epoch 19/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.7907 - acc: 0.6153 - val_loss: 1.3580 - val_acc: 0.3829\n",
      "Epoch 20/50\n",
      "1258/1258 [==============================] - 82s - loss: 0.7843 - acc: 0.6169 - val_loss: 1.5277 - val_acc: 0.3964\n",
      "Epoch 21/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.7900 - acc: 0.6057 - val_loss: 1.3388 - val_acc: 0.3784\n",
      "Epoch 22/50\n",
      "1258/1258 [==============================] - 82s - loss: 0.7613 - acc: 0.6073 - val_loss: 1.4083 - val_acc: 0.3694\n",
      "Epoch 23/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.7354 - acc: 0.6423 - val_loss: 1.6350 - val_acc: 0.4369\n",
      "Epoch 24/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.7350 - acc: 0.6407 - val_loss: 1.6877 - val_acc: 0.3964\n",
      "Epoch 25/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.7399 - acc: 0.6423 - val_loss: 1.5802 - val_acc: 0.4550\n",
      "Epoch 26/50\n",
      "1258/1258 [==============================] - 82s - loss: 0.7203 - acc: 0.6439 - val_loss: 1.5509 - val_acc: 0.3649\n",
      "Epoch 27/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.7046 - acc: 0.6486 - val_loss: 1.3517 - val_acc: 0.4009\n",
      "Epoch 28/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.6990 - acc: 0.6486 - val_loss: 1.6466 - val_acc: 0.4054\n",
      "Epoch 29/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.6710 - acc: 0.6614 - val_loss: 1.6045 - val_acc: 0.3919\n",
      "Epoch 30/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.6720 - acc: 0.6630 - val_loss: 1.9495 - val_acc: 0.3829\n",
      "Epoch 31/50\n",
      "1258/1258 [==============================] - 98s - loss: 0.6396 - acc: 0.6812 - val_loss: 1.6827 - val_acc: 0.3468\n",
      "Epoch 32/50\n",
      "1258/1258 [==============================] - 114s - loss: 0.6332 - acc: 0.6757 - val_loss: 1.5344 - val_acc: 0.4009\n",
      "Epoch 33/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.6177 - acc: 0.6987 - val_loss: 2.0780 - val_acc: 0.3604\n",
      "Epoch 34/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.6063 - acc: 0.6868 - val_loss: 1.7177 - val_acc: 0.3694\n",
      "Epoch 35/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.6078 - acc: 0.6820 - val_loss: 1.7360 - val_acc: 0.4009\n",
      "Epoch 36/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.5897 - acc: 0.6987 - val_loss: 1.8091 - val_acc: 0.4054\n",
      "Epoch 37/50\n",
      "1258/1258 [==============================] - 82s - loss: 0.5897 - acc: 0.7019 - val_loss: 2.0608 - val_acc: 0.4144\n",
      "Epoch 38/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.5804 - acc: 0.7146 - val_loss: 1.7199 - val_acc: 0.4414\n",
      "Epoch 39/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.5605 - acc: 0.7289 - val_loss: 2.6270 - val_acc: 0.3514\n",
      "Epoch 40/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.5646 - acc: 0.7043 - val_loss: 2.1951 - val_acc: 0.4054\n",
      "Epoch 41/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.5521 - acc: 0.7194 - val_loss: 1.9164 - val_acc: 0.4640\n",
      "Epoch 42/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.5533 - acc: 0.7337 - val_loss: 2.3004 - val_acc: 0.3694\n",
      "Epoch 43/50\n",
      "1258/1258 [==============================] - 82s - loss: 0.5391 - acc: 0.7258 - val_loss: 1.9866 - val_acc: 0.4054\n",
      "Epoch 44/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.5233 - acc: 0.7297 - val_loss: 2.6739 - val_acc: 0.3604\n",
      "Epoch 45/50\n",
      "1258/1258 [==============================] - 82s - loss: 0.5124 - acc: 0.7345 - val_loss: 2.1270 - val_acc: 0.4234\n",
      "Epoch 46/50\n",
      "1258/1258 [==============================] - 82s - loss: 0.4781 - acc: 0.7742 - val_loss: 2.3427 - val_acc: 0.4324\n",
      "Epoch 47/50\n",
      "1258/1258 [==============================] - 85s - loss: 0.5071 - acc: 0.7488 - val_loss: 2.5739 - val_acc: 0.3964\n",
      "Epoch 48/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.4874 - acc: 0.7591 - val_loss: 2.6112 - val_acc: 0.4595\n",
      "Epoch 49/50\n",
      "1258/1258 [==============================] - 81s - loss: 0.4862 - acc: 0.7576 - val_loss: 2.7854 - val_acc: 0.4054\n",
      "Epoch 50/50\n",
      "1258/1258 [==============================] - 82s - loss: 0.4688 - acc: 0.7639 - val_loss: 1.9872 - val_acc: 0.4414\n"
     ]
    }
   ],
   "source": [
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "\n",
    "train_data = np.load(open('bottleneck_features_train.npy'))\n",
    "validation_data = np.load(open('bottleneck_features_validation.npy'))\n",
    "y_train = np.load(open('y_train.npy'))\n",
    "y_validation = np.load(open('y_validation.npy'))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adadelta(),\n",
    "                  loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, y_train,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              verbose=1,\n",
    "              validation_data=(validation_data, y_validation))\n",
    "model.save_weights(top_model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = np.load(open('x_train.npy'))\n",
    "x_validation = np.load(open('x_validation.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riccardosamperna/Programming/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:23: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"se..., inputs=Tensor(\"in...)`\n",
      "/Users/riccardosamperna/Programming/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:71: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=<keras.pre..., steps_per_epoch=157, epochs=50, validation_steps=222)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "157/157 [==============================] - 8944s - loss: 1.3303 - acc: 0.3583 - val_loss: 1.7568 - val_acc: 0.3337\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 9087s - loss: 1.3162 - acc: 0.3941 - val_loss: 1.7545 - val_acc: 0.3341\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 9017s - loss: 1.3000 - acc: 0.3718 - val_loss: 1.7609 - val_acc: 0.3347\n",
      "Epoch 4/50\n",
      "156/157 [============================>.] - ETA: 24s - loss: 1.3506 - acc: 0.3886"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-7c42798c1d0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     nb_val_samples=222)\n\u001b[0m",
      "\u001b[0;32m/Users/riccardosamperna/.local/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/riccardosamperna/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1897\u001b[0m                                 \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1898\u001b[0m                                 \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1899\u001b[0;31m                                 pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m   1900\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m                             \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/riccardosamperna/.local/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/riccardosamperna/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_q_size, workers, pickle_safe)\u001b[0m\n\u001b[1;32m   1994\u001b[0m                                      \u001b[0;34m'or (x, y). Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m                                      str(generator_output))\n\u001b[0;32m-> 1996\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1998\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/riccardosamperna/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtest_on_batch\u001b[0;34m(self, x, y, sample_weight)\u001b[0m\n\u001b[1;32m   1661\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1662\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1663\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1664\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1665\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/riccardosamperna/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2103\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/riccardosamperna/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/riccardosamperna/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/riccardosamperna/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/riccardosamperna/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/riccardosamperna/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "weights_path = './vgg16_weights.h5'\n",
    "\n",
    "# build the VGG16 network\n",
    "input_tensor = Input(shape=(400,400,3))\n",
    "base_model = applications.VGG16(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
    "print('Model loaded.')\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "# note that it is necessary to start with a fully-trained\n",
    "# classifier, including the top classifier,\n",
    "# in order to successfully do fine-tuning\n",
    "top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "model = Model(input= base_model.input, output= top_model(base_model.output))\n",
    "\n",
    "# # build a classifier model to put on top of the convolutional model\n",
    "# x = base_model.output\n",
    "# x = Flatten()(x)\n",
    "# x = Dense(256, activation='relu') (x)\n",
    "# x = Dropout(0.5) (x)\n",
    "# predictions = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# # note that it is necessary to start with a fully-trained\n",
    "# # classifier, including the top classifier,\n",
    "# # in order to successfully do fine-tuning\n",
    "# x.load_weights(top_model_weights_path)\n",
    "\n",
    "# # add the model on top of the convolutional base\n",
    "# model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow(x_validation, y_validation, batch_size=batch_size)\n",
    "\n",
    "# fine-tune the model\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=1258,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    nb_val_samples=222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
